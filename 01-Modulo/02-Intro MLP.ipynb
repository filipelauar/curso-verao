{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02-Intro MLP.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NG-mVsVuE0if","colab_type":"text"},"source":["# Preâmbulo\n","\n","Imports, funções, downloads e instalação do Pytorch."]},{"cell_type":"code","metadata":{"id":"FQ65_lev3RXO","colab_type":"code","colab":{}},"source":["# Reinstalling torch with the right CUDA bindings.\n","# !pip3 install -U https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n","# !pip3 install -U https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEHmMCjR4PJw","colab_type":"code","colab":{}},"source":["# Basic imports.\n","import os\n","import time\n","import numpy as np\n","import torch\n","\n","import torch\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","\n","from torch import nn\n","from torch import optim\n","\n","from torch.utils.data import DataLoader\n","from torch.utils import data\n","from torch.backends import cudnn\n","\n","from torchvision import models\n","from torchvision import datasets\n","from torchvision import transforms\n","\n","from skimage import io\n","\n","from sklearn import metrics\n","\n","from matplotlib import pyplot as plt\n","\n","%matplotlib inline\n","\n","cudnn.benchmark = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQa4-lUw7Rmp","colab_type":"text"},"source":["## Casting para o dispositivo correto\n","\n","Como usaremos processamento vetorial principalmente em GPUs para aprendizado profundo, primeiramente é possível verificar se há uma GPU disponível com o trecho de código abaixo, armazenando os tensores nos dispositivos apropriados."]},{"cell_type":"code","metadata":{"id":"yX0bBEM863sY","colab_type":"code","colab":{}},"source":["# Checking if GPU/CUDA is available.\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","print(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1x5UK0uib2tk","colab_type":"text"},"source":["# O perceptron e a camada linear\n","A camada Linear do Pytorch ([nn.Linear](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear)) é responsável por aplicar uma transformação linear no dado de entrada. Esta camada recebe como parâmetro a dimensão (número de *features*) da entrada e da saída. Por padrão o bias já é incluído. Um perceptron pode ser facilmente representado como a seguir, desconsiderando a função de ativação:\n","\n","```\n","perceptron = nn.Linear(in_dimension, 1)\n","```\n","Mas de uma forma geral, uma camada Linear com diversas *features* de entrada e diversas *features* de saída pode ser representada como:\n","```\n","nn.Linear(in_features, out_features)\n","```\n","![](./figs/nn_linear.png)"]},{"cell_type":"code","metadata":{"id":"OlQA_vtGg8bf","colab_type":"code","colab":{}},"source":["linear = nn.Linear(2,3)\n","print(linear)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6AhNyLrLmFcT","colab_type":"text"},"source":["Como é possível ver no código abaixo, o Pytorch já inicia os pesos da camada aleatoriamente."]},{"cell_type":"code","metadata":{"id":"fLOlOhQVmPuj","colab_type":"code","colab":{}},"source":["for p in linear.parameters():\n","  print(p)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aAEaJGtDoZD7","colab_type":"text"},"source":["O **forward** consiste em passar seu dado de entrada pela rede, gerando um resultado ao final. Considerando a camada linear instanciada anteriormente, o resultado do forward é o mesmo do somatório da multiplicação de seus pesos pelas respectivas entradas juntamente com o bias:\n","\n","w1\\*x1 + w2\\*x2 + ... + wn\\*xn + b\n","\n","No Pytorch, realizamos o **forward** chamando a função onde nossa rede/modelo está instanciada, conforme exemplo abaixo."]},{"cell_type":"code","metadata":{"id":"Ibb8t7zpmpUI","colab_type":"code","colab":{}},"source":["perceptron = nn.Linear(2,1)\n","X = torch.FloatTensor([2,3]) #dado de entrada de exemplo considernado o perceptron definido como nn.Linear(2,1)\n","print('Pytorch: ', perceptron(X))\n","\n","# acessamos os pesos do modelo com .weight e o bias com .bias\n","print('Manual: ', torch.mul(X, perceptron.weight).sum() + perceptron.bias)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x8LMX6OMrEbw","colab_type":"text"},"source":["# Exemplo Perceptron simples\n","Modifique o código abaixo para que ele realize o forward na camada Linear e calcule a loss"]},{"cell_type":"code","metadata":{"id":"YPJ9s5ckoA5T","colab_type":"code","colab":{}},"source":["def loss_fn(predict, label):\n","    return torch.pow(label - predict, 2)\n","\n","perceptron = nn.Linear(1,1) # Camada linear com 1 feature de entrada (mais o bias) e uma de saída\n","perceptron.to(device) # casting do perceptron para GPU\n","learning_rate = 0.01\n","print('Parametros iniciais: ', list(perceptron.parameters()))\n","\n","dataset = [] # dados de exemplo quer seguirão a função y = 2x+3\n","for x in range(10):\n","    dataset.append((x, 2*x+3))\n","\n","for epoch in range(101):\n","    epoch_loss = 0\n","    for iteration, data in enumerate(dataset):\n","        X, y = data\n","        X, y = torch.FloatTensor([X]).to(device), torch.FloatTensor([y]).to(device) # conversão para Tensor\n","        \n","        ###########\n","        # IMPLEMENTE AQUI SUA PARTE DA SOLUÇÃO\n","        ###########\n","\n","        epoch_loss += loss.item()\n","        loss.backward()\n","        with torch.no_grad():\n","            for param in perceptron.parameters():\n","                param -= learning_rate * param.grad # atualização dos parametros (pesos e bias) com base no gradiente\n","                param.grad.zero_() # resetando o gradiente\n","\n","    if epoch % 10 == 0:\n","        print(\"Epoch {} - loss: {}\".format(epoch, epoch_loss))\n","print('Parametros finais: ', list(perceptron.parameters()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9uRk8mAwGIB","colab_type":"code","colab":{}},"source":["print(perceptron(torch.FloatTensor([20]).to(device))) #forward do valor 20 para conferir resultado"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3f-q6bCNzEmx","colab_type":"text"},"source":["# Sequential\n","Na prática, criaremos redes com diversas camadas. O bloco nn.Sequential permite agrupar as camadas de forma sequencial para que o forward seja realizado na ordem desejada automaticamente. Veja um exemplo para um *Multilayer Perceptron (MLP)* abaixo."]},{"cell_type":"code","metadata":{"id":"LCK_OkqCzdUW","colab_type":"code","colab":{}},"source":["in_features = 28\n","hidden_1 = 64\n","hidden_2 = 32\n","out_features = 8\n","\n","MLP = nn.Sequential(nn.Linear(in_features, hidden_1), nn.ReLU(), \n","                    nn.Linear(hidden_1, hidden_2), nn.ReLU(), \n","                    nn.Linear(hidden_2, out_features))\n","print(MLP)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkhjCepK0kjJ","colab_type":"code","colab":{}},"source":["test_data = torch.randn((10,28)) # 10 dados de input aleatórios com 28 features\n","output = MLP(test_data) # forward da rede\n","print(output.size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E9LoXL0cUYMT","colab_type":"text"},"source":["## Treinando uma MLP simples em dados aleatórios"]},{"cell_type":"code","metadata":{"id":"Vi3Zh8fQ4X_3","colab_type":"code","colab":{}},"source":["# N is batch size; D_in is input dimension;\n","# H is hidden dimension; D_out is output dimension.\n","N, D_in, H, D_out = 64, 1000, 100, 10\n","\n","# Create random Tensors to hold inputs and outputs\n","x = torch.randn(N, D_in)\n","y = torch.randn(N, D_out)\n","\n","# Casting tensors to the appropriate device.\n","x = x.to(device)\n","y = y.to(device)\n","\n","# Printing sizes of tensors.\n","print('x: ', x.size())\n","print('y: ', y.size())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZMDN1viW-0Eg","colab_type":"text"},"source":["## Definindo arquitetura, loss e otimizador\n","Modifique o código abaixo para criar um container *Sequential* de nome **model** que representa uma MLP com uma camada escondida (seguindo os valores N, D_in, H e D_out definidos anteriormente),**usando um ReLU como função de ativação entre as camadas**.\n","\n","**Dica:** não se esqueça de realizar o casting da rede para GPU com o comando .to(device)\n","\n","![](./figs/mlp.png)"]},{"cell_type":"code","metadata":{"id":"zYO7HWC29Ahy","colab_type":"code","colab":{}},"source":["# Use the nn package to define our model.\n","model = # IMPLEMENTE AQUI SUA SOLUÇÃO\n","\n","print(model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1oQ2T8jm9BE9","colab_type":"code","colab":{}},"source":["# Use the nn package to define our loss function.\n","loss_mse = nn.MSELoss(reduction='sum').to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oa5DcYBf82iD","colab_type":"code","colab":{}},"source":["# Use the optim package to define an Optimizer that will update the weights of\n","# the model for us. Here we will use SGD; the optim package contains many other\n","# optimization algorithms. The first argument tells the\n","# optimizer which Tensors it should update.\n","learning_rate = 1e-4\n","\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JPQtOnNr-kAG","colab_type":"text"},"source":["## Minimizando o erro entre $f(x)$ e $y$\n","\n","Implemente abaixo a forward e cálculo da loss."]},{"cell_type":"code","metadata":{"id":"dsMFRIDv80I3","colab_type":"code","colab":{}},"source":["# Creating list of losses for each epoch.\n","loss_list = []\n","\n","# Iterating over epochs.\n","for epoch in range(500):\n","    \n","    ###########\n","    # Implemente sua solução aqui\n","    ###########\n","    \n","    if (epoch + 1) % 10 == 0:\n","        print('Epoch ' + str(epoch + 1) + ': loss = ' + str(loss.item()))\n","    \n","    # Updating list of losses for printing.\n","    loss_list.append(loss.item())\n","\n","    # Before the backward pass, use the optimizer object to zero all of the\n","    # gradients for the variables it will update (which are the learnable\n","    # weights of the model). This is because by default, gradients are\n","    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n","    # is called. Checkout docs of torch.autograd.backward for more details.\n","    optimizer.zero_grad()\n","\n","    # Backward pass: compute gradient of the loss with respect to model\n","    # parameters\n","    loss.backward()\n","\n","    # Calling the step function on an Optimizer makes an update to its\n","    # parameters\n","    optimizer.step()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"toQyqq98-68X","colab_type":"code","colab":{}},"source":["fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n","\n","ax.plot(np.asarray(loss_list))\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dfb4zBjO0Lua","colab_type":"text"},"source":["Informação sobre outras camadas lineares, como nn.Bilinear e nn.Identity, podem ser vistas na documentação: https://pytorch.org/docs/stable/nn.html#linear-layers"]}]}